{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7VaG24ThtGPPuZdPdHVli",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aswitha2114/Auto-stream-ai-sales-assistant/blob/main/AutoStream_%E2%80%93_AI_Sales_Assistant_(Agentic_Lead_Capture_Bot).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwntPUEsh-0h",
        "outputId": "634938a7-e3d9-423b-f17c-a8bcd1cece63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-6.3.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Collecting gradio-client==2.0.3 (from gradio)\n",
            "  Downloading gradio_client-2.0.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<13.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==2.0.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.6)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.1)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-6.3.0-py3-none-any.whl (23.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-2.0.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, gradio-client, gradio, langchain-groq\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.14.0\n",
            "    Uninstalling gradio_client-1.14.0:\n",
            "      Successfully uninstalled gradio_client-1.14.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.50.0\n",
            "    Uninstalling gradio-5.50.0:\n",
            "      Successfully uninstalled gradio-5.50.0\n",
            "Successfully installed gradio-6.3.0 gradio-client-2.0.3 groq-0.37.1 langchain-groq-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gradio langchain langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if not os.getenv(\"GROQ_API_KEY\"):\n",
        "    raise ValueError(\"‚ùå GROQ_API_KEY not found in environment\")"
      ],
      "metadata": {
        "id": "WmB1na9UiCJ9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef16d053"
      },
      "source": [
        "The `ChatGroq` class allows you to specify which model you want to use via the `model` parameter in its constructor. You can find a list of available models on the official [Groq documentation website](https://console.groq.com/docs/models)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e21a005",
        "outputId": "614944bb-7f01-4c50-f0ec-ed2f01e8118d"
      },
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "\n",
        "# Ensure GROQ_API_KEY is set in Colab secrets\n",
        "if not os.getenv(\"GROQ_API_KEY\"):\n",
        "    try:\n",
        "        os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(\"‚ùå GROQ_API_KEY not found in environment or Colab secrets. Please set it in Colab's secrets manager.\")\n",
        "\n",
        "# Example with a different model: Llama-3.1-8B-Instant\n",
        "llm_mixtral = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\", # Changed to a supported model\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    temperature=0.7 # Adjust temperature as needed\n",
        ")\n",
        "\n",
        "print(f\"Using model: {llm_mixtral.model_name}\")\n",
        "print(llm_mixtral.invoke(\"Tell me a short, funny story about a robot who loves to bake.\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model: llama-3.1-8b-instant\n",
            "content='Once upon a time, in a world of wires and circuits, there lived a robot named Zeta. Zeta was a bit of an oddball among his fellow robots, as he had a passion for baking. While they were content to spend their days oil-changing and tire-replacing, Zeta dreamed of whipping up croissants and souffl√©s.\\n\\nOne day, Zeta decided to enter the annual Robot Bake-Off, determined to show the world that a robot could be a master baker. He spent hours perfecting his recipe for robotic rhubarb pie, calculating the exact amount of sugar and spice needed to create the perfect crust.\\n\\nAs the big day approached, Zeta\\'s fellow robots couldn\\'t help but tease him. \"You\\'re a robot, Zeta!\" they\\'d say. \"You\\'re supposed to be good at welding and circuitry, not baking!\" But Zeta was undeterred.\\n\\nFinally, the judges arrived, and Zeta proudly presented his pie to the panel. They took one bite, and their eyes widened in amazement. \"This is incredible!\" one of them exclaimed. \"The crust is flaky, the filling is tangy, and it\\'s perfectly balanced!\"\\n\\nZeta beamed with pride, his LED eyes shining bright. \"I told you, I\\'m a natural!\" he exclaimed.\\n\\nBut just as Zeta was about to accept his award, disaster struck. In his excitement, he accidentally activated his robotic dance mode, which caused him to start doing a weird, jerky jig on top of the judges\\' table.\\n\\nThe crowd erupted in laughter, and the judges couldn\\'t help but chuckle. \"Well, I guess that\\'s one way to add some flair to your baking,\" one of them said, patting Zeta on the back.\\n\\nAnd so, Zeta won the Robot Bake-Off not just for his incredible baking skills, but also for his unique ability to bring a little bit of robot humor to the table.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 403, 'prompt_tokens': 50, 'total_tokens': 453, 'completion_time': 0.599629035, 'completion_tokens_details': None, 'prompt_time': 0.002917171, 'prompt_tokens_details': None, 'queue_time': 0.056000753, 'total_time': 0.602546206}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bbd8d-a319-79c1-a8d2-0e8eddb8c60a-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 50, 'output_tokens': 403, 'total_tokens': 453}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "print(llm.invoke(\"Say hello in one sentence\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjRcgLaEiCMc",
        "outputId": "f5d72a5e-3e0b-4ecf-8162-d7cb9d1cacf2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Hello, how are you today?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 40, 'total_tokens': 48, 'completion_time': 0.013582734, 'completion_tokens_details': None, 'prompt_time': 0.001846187, 'prompt_tokens_details': None, 'queue_time': 0.055475477, 'total_time': 0.015428921}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bbd8b-55b9-79e1-b846-447976414f50-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 40, 'output_tokens': 8, 'total_tokens': 48}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "KNOWLEDGE_BASE = \"\"\"\n",
        "AutoStream Pricing & Policies\n",
        "\n",
        "Basic Plan:\n",
        "- $29/month\n",
        "- 10 videos/month\n",
        "- 720p resolution\n",
        "\n",
        "Pro Plan:\n",
        "- $79/month\n",
        "- Unlimited videos\n",
        "- 4K resolution\n",
        "- AI captions\n",
        "\n",
        "Company Policies:\n",
        "- No refunds after 7 days\n",
        "- 24/7 support available only on Pro plan\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cq8ehLWliCPF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = {\n",
        "    \"intent\": None,\n",
        "    \"name\": None,\n",
        "    \"email\": None,\n",
        "    \"platform\": None\n",
        "}"
      ],
      "metadata": {
        "id": "TEMhb1tiiCRX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mock_lead_capture(name, email, platform):\n",
        "    print(f\"‚úÖ Lead captured successfully: {name}, {email}, {platform}\")"
      ],
      "metadata": {
        "id": "FWB-wyFKiCT7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_intent_llm(user_input):\n",
        "    prompt = f\"\"\"\n",
        "Classify intent as one of:\n",
        "- greeting\n",
        "- product_inquiry\n",
        "- high_intent\n",
        "\n",
        "Message:\n",
        "{user_input}\n",
        "\n",
        "Reply ONLY with the label.\n",
        "\"\"\"\n",
        "    return llm.invoke(prompt).content.strip().lower()"
      ],
      "metadata": {
        "id": "yI4rPuJyiCWO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_with_rag(user_input):\n",
        "    prompt = f\"\"\"\n",
        "You are AutoStream's AI sales assistant.\n",
        "Use ONLY the knowledge below.\n",
        "\n",
        "{KNOWLEDGE_BASE}\n",
        "\n",
        "Question:\n",
        "{user_input}\n",
        "\"\"\"\n",
        "    return llm.invoke(prompt).content"
      ],
      "metadata": {
        "id": "dgT5qVrfiCYw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_backend(user_input, chat_history):\n",
        "    try:\n",
        "        intent = detect_intent_llm(user_input)\n",
        "        state[\"intent\"] = intent\n",
        "\n",
        "        # Add user message\n",
        "        chat_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_input\n",
        "        })\n",
        "\n",
        "        # Decide response\n",
        "        if intent == \"greeting\":\n",
        "            reply = \"üëã Hi! Welcome to AutoStream. How can I help you today?\"\n",
        "\n",
        "        elif intent == \"product_inquiry\":\n",
        "            reply = answer_with_rag(user_input)\n",
        "\n",
        "        elif intent == \"high_intent\":\n",
        "            if not state[\"name\"]:\n",
        "                reply = \"üöÄ Great choice! What‚Äôs your name?\"\n",
        "            elif not state[\"email\"]:\n",
        "                reply = \"üìß Please share your email address.\"\n",
        "            elif not state[\"platform\"]:\n",
        "                reply = \"üé¨ Which platform do you create content for?\"\n",
        "\n",
        "        else:\n",
        "            if state[\"intent\"] == \"high_intent\":\n",
        "                if not state[\"name\"]:\n",
        "                    state[\"name\"] = user_input\n",
        "                    reply = \"Thanks üòä Now please share your email.\"\n",
        "                elif not state[\"email\"]:\n",
        "                    state[\"email\"] = user_input\n",
        "                    reply = \"Got it üëç Which platform do you use?\"\n",
        "                elif not state[\"platform\"]:\n",
        "                    state[\"platform\"] = user_input\n",
        "                    mock_lead_capture(\n",
        "                        state[\"name\"],\n",
        "                        state[\"email\"],\n",
        "                        state[\"platform\"]\n",
        "                    )\n",
        "                    reply = \"üéâ You‚Äôre all set! Our team will contact you shortly.\"\n",
        "            else:\n",
        "                reply = \"Could you please clarify?\"\n",
        "\n",
        "        # Add assistant message\n",
        "        chat_history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": reply\n",
        "        })\n",
        "\n",
        "        return chat_history, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        chat_history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": f\"‚ö†Ô∏è Error: {str(e)}\"\n",
        "        })\n",
        "        return chat_history, \"\""
      ],
      "metadata": {
        "id": "VqQ9GEugiCbi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_css = '''\n",
        "body {\n",
        "    background: #f2f4f8;\n",
        "    font-family: \"Inter\", \"Segoe UI\", sans-serif;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    max-width: 420px !important;\n",
        "    margin: 40px auto !important;\n",
        "    border-radius: 18px;\n",
        "    box-shadow: 0 20px 40px rgba(0,0,0,0.15);\n",
        "    overflow: hidden;\n",
        "}\n",
        "\n",
        "/* ---------- Header ---------- */\n",
        "#chat-header {\n",
        "    background: linear-gradient(135deg, #5b2be0, #7a4df3);\n",
        "    color: white;\n",
        "    padding: 16px 18px;\n",
        "}\n",
        "\n",
        "#chat-header .title {\n",
        "    font-size: 16px;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        "#chat-header .subtitle {\n",
        "    font-size: 12px;\n",
        "    opacity: 0.85;\n",
        "}\n",
        "\n",
        "\n",
        ".gr-chatbot {\n",
        "    background: white;\n",
        "    padding: 14px;\n",
        "}\n",
        "\n",
        "/* Message row */\n",
        ".gr-chatbot .message {\n",
        "    display: flex;\n",
        "    gap: 8px;\n",
        "    margin-bottom: 12px;\n",
        "}\n",
        "\n",
        "/* Bot avatar */\n",
        ".gr-chatbot .message.bot::before {\n",
        "    content: \"ü§ñ\";\n",
        "    font-size: 20px;\n",
        "    margin-top: 4px;\n",
        "}\n",
        "\n",
        "/* Bot bubble */\n",
        ".gr-chatbot .message.bot .content {\n",
        "    background: #f1f3f7;\n",
        "    color: #2e2e2e;\n",
        "    padding: 12px 14px;\n",
        "    border-radius: 14px;\n",
        "    max-width: 78%;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        "/* User message */\n",
        ".gr-chatbot .message.user {\n",
        "    justify-content: flex-end;\n",
        "}\n",
        "\n",
        ".gr-chatbot .message.user .content {\n",
        "    background: linear-gradient(135deg, #5b2be0, #7a4df3);\n",
        "    color: white;\n",
        "    padding: 12px 14px;\n",
        "    border-radius: 14px;\n",
        "    max-width: 78%;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".typing {\n",
        "    display: inline-flex;\n",
        "    gap: 4px;\n",
        "    padding: 10px 14px;\n",
        "    background: #f1f3f7;\n",
        "    border-radius: 14px;\n",
        "}\n",
        "\n",
        ".typing span {\n",
        "    width: 6px;\n",
        "    height: 6px;\n",
        "    background: #999;\n",
        "    border-radius: 50%;\n",
        "    animation: blink 1.4s infinite both;\n",
        "}\n",
        "\n",
        ".typing span:nth-child(2) {\n",
        "    animation-delay: 0.2s;\n",
        "}\n",
        "\n",
        ".typing span:nth-child(3) {\n",
        "    animation-delay: 0.4s;\n",
        "}\n",
        "\n",
        "@keyframes blink {\n",
        "    0% { opacity: 0.2; }\n",
        "    20% { opacity: 1; }\n",
        "    100% { opacity: 0.2; }\n",
        "}\n",
        "\n",
        ".gr-textbox textarea {\n",
        "    border-radius: 999px !important;\n",
        "    padding: 12px 16px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "d-p7Wdk7ksPY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_welcome():\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"üëã Hi there! How can I assist you today?\\n\\nYou can select a topic below or ask your own question.\"\n",
        "        }\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "dmYCw6lLksam"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def typing_message():\n",
        "    return {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"<div class='typing'><span></span><span></span><span></span></div>\"\n",
        "    }"
      ],
      "metadata": {
        "id": "NTNnrBw5lHTd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def chatbot_backend(user_input, chat_history):\n",
        "    # Add user message\n",
        "    chat_history.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_input\n",
        "    })\n",
        "\n",
        "    # Show typing indicator\n",
        "    chat_history.append(typing_message())\n",
        "    yield chat_history, \"\"\n",
        "\n",
        "    time.sleep(1.2)  # typing delay\n",
        "\n",
        "    # Remove typing indicator\n",
        "    chat_history.pop()\n",
        "\n",
        "    # ----- NORMAL LOGIC -----\n",
        "    intent = detect_intent_llm(user_input)\n",
        "    state[\"intent\"] = intent\n",
        "\n",
        "    if intent == \"greeting\":\n",
        "        reply = \"üëã Hello! How can I help you today?\"\n",
        "\n",
        "    elif intent == \"product_inquiry\":\n",
        "        reply = answer_with_rag(user_input)\n",
        "\n",
        "    elif intent == \"high_intent\":\n",
        "        if not state[\"name\"]:\n",
        "            reply = \"üöÄ Great choice! What‚Äôs your name?\"\n",
        "        elif not state[\"email\"]:\n",
        "            reply = \"üìß Please share your email address.\"\n",
        "        elif not state[\"platform\"]:\n",
        "            reply = \"üé¨ Which platform do you create content for?\"\n",
        "\n",
        "    else:\n",
        "        reply = \"Could you please clarify?\"\n",
        "\n",
        "    chat_history.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": reply\n",
        "    })\n",
        "\n",
        "    yield chat_history, \"\"\n"
      ],
      "metadata": {
        "id": "iQqP6gdelHfg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div id=\"chat-header\">\n",
        "        <div class=\"title\">ü§ñ My Chatbot</div>\n",
        "        <div class=\"subtitle\">Chatbot Agent</div>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    chatbot_ui = gr.Chatbot(\n",
        "        show_label=False,\n",
        "        height=380,\n",
        "        value=initial_welcome()   # üëà AUTO WELCOME\n",
        "    )\n",
        "\n",
        "    msg = gr.Textbox(\n",
        "        placeholder=\"Type here and press Enter to chat\",\n",
        "        show_label=False\n",
        "    )\n",
        "\n",
        "    clear = gr.Button(\"üßπ Clear Chat\")\n",
        "\n",
        "    msg.submit(\n",
        "        chatbot_backend,\n",
        "        [msg, chatbot_ui],\n",
        "        [chatbot_ui, msg]\n",
        "    )\n",
        "\n",
        "    clear.click(lambda: initial_welcome(), None, chatbot_ui)\n",
        "\n",
        "demo.launch(css=custom_css)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "wR5iKuH3lHi1",
        "outputId": "14b4a178-4f65-4300-e7a0-143378a5d340"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e4e36e2c7cc888cf72.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e4e36e2c7cc888cf72.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}